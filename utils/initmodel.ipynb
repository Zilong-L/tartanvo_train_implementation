{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 添加模块搜索路径\n",
    "module_path = '/home/lzl/code/python/tartanvo_train_implementation'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYTHONPATH']='/home/lzl/code/python/tartanvo_train_implementation'\n",
    "import torch\n",
    "import sys\n",
    "import toml\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.tensorboard import SummaryWriter   \n",
    "\n",
    "from Network.VONet import VONet\n",
    "\n",
    "from utils.train_pose_utils import load_from_file,load_model, save_model, train_pose_batch, validate\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, optimizer=None, scheduler=None, filepath=\"\"):\n",
    "    \"\"\"\n",
    "    加载模型、优化器和调度器的状态\n",
    "\n",
    "    参数:\n",
    "    model (torch.nn.Module): 要加载状态的模型\n",
    "    optimizer (torch.optim.Optimizer): 要加载状态的优化器\n",
    "    scheduler (torch.optim.lr_scheduler._LRScheduler): 要加载状态的调度器\n",
    "    filepath (str): 要加载文件的路径\n",
    "\n",
    "    返回:\n",
    "    int: 加载的epoch\n",
    "    int: 加载的迭代步数\n",
    "    \"\"\"\n",
    "    if filepath==\"\":\n",
    "        return 0,0\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if scheduler is not None:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    epoch = checkpoint['epoch']  # 如果epoch没保存，默认值为0\n",
    "    iteration = checkpoint['iteration']\n",
    "    print(f\"successfully load model from {filepath}\")\n",
    "    return epoch+1, iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzl/miniforge3/envs/311/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    }
   ],
   "source": [
    "model = VONet()\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwcweight = torch.load('/home/lzl/code/python/tartanvo_train_implementation/models/pwcdcnet/pwc_net_chairs.pth.tar')\n",
    "flowposeweight = torch.load('/home/lzl/code/python/tartanvo_train_implementation/models/POSEONLY_NORCR/flowpose_model_iteration_99844.pth')\n",
    "strippedFlowPose = {k.replace('module.',''):v for k,v in flowposeweight['model_state_dict'].items()}\n",
    "model.module.flowNet.load_state_dict(pwcweight)\n",
    "model.module.flowPoseNet.load_state_dict(strippedFlowPose)\n",
    "torch.save({\n",
    "    'model_state_dict': model.module.state_dict(),\n",
    "    'optimizer_state_dict': None,\n",
    "    'scheduler_state_dict': None,\n",
    "    'epoch': 0,\n",
    "    'iteration': 0\n",
    "},'/home/lzl/code/python/tartanvo_train_implementation/models/whole_no_rcr/init.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwcweight = torch.load('/home/lzl/code/python/tartanvo_train_implementation/models/pwcdcnet/pwc_net_chairs.pth.tar')\n",
    "flowposeweight = torch.load('/home/lzl/code/python/tartanvo_train_implementation/models/POSEONLY_RCR/flowpose_model_iteration_99844.pth')\n",
    "strippedFlowPose = {k.replace('module.',''):v for k,v in flowposeweight['model_state_dict'].items()}\n",
    "model.module.flowNet.load_state_dict(pwcweight)\n",
    "model.module.flowPoseNet.load_state_dict(strippedFlowPose)\n",
    "torch.save({\n",
    "    'model_state_dict': model.module.state_dict(),\n",
    "    'optimizer_state_dict': None,\n",
    "    'scheduler_state_dict': None,\n",
    "    'epoch': 0,\n",
    "    'iteration': 0\n",
    "},'/home/lzl/code/python/tartanvo_train_implementation/models/whole_rcr/init.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tartan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
